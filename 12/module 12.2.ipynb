{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hst):\n",
    "    plt.figure(figsize=(13, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hst.history['loss'], label='train')\n",
    "    plt.plot(hst.history['val_loss'], label='test')\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([round(100*e, 2) for e in hst.history['sparse_categorical_accuracy']], label='train')\n",
    "    plt.plot([round(100*e, 2) for e in hst.history['val_sparse_categorical_accuracy']], label='test')\n",
    "    plt.title('Accuracy')    \n",
    "\n",
    "    plt.ylim(0, 100)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "N = 30000\n",
    "\n",
    "x_train = x_train[:N] / 255\n",
    "x_test = x_test[:N] / 255\n",
    "\n",
    "y_train = y_train[:N]\n",
    "y_test = y_test[:N]\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = {}\n",
    "\n",
    "optimizers_list = [\n",
    "    tf.keras.optimizers.Adam,\n",
    "    tf.keras.optimizers.Adagrad,\n",
    "    tf.keras.optimizers.AdamW,\n",
    "    tf.keras.optimizers.Adamax,\n",
    "    tf.keras.optimizers.Ftrl,\n",
    "    tf.keras.optimizers.Lion,\n",
    "    tf.keras.optimizers.Nadam,\n",
    "    tf.keras.optimizers.RMSprop,\n",
    "    tf.keras.optimizers.SGD\n",
    "]\n",
    "\n",
    "for opt in optimizers_list:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=opt(learning_rate=0.001),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)\n",
    "    print(opt.__name__)\n",
    "    plot_history(history)\n",
    "    collect[opt.__name__] = history.history['val_sparse_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(collect).T.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect = {}\n",
    "\n",
    "activation_list = [\n",
    "    'linear',\n",
    "    'relu',\n",
    "    'tanh',\n",
    "    'elu',\n",
    "    'softplus',\n",
    "    'sigmoid'\n",
    "]\n",
    "\n",
    "for act in activation_list:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=act),\n",
    "        tf.keras.layers.Dense(64, activation=act),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)\n",
    "    print(act)\n",
    "    plot_history(history)\n",
    "    collect[act] = history.history['val_sparse_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(collect).T.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input = Input(shape=(28, 28))\n",
    "\n",
    "flatten = Flatten(input_shape=(28, 28))(input)\n",
    "\n",
    "dense1 = Dense(units=128, activation='relu')(flatten)\n",
    "dense2 = Dense(units=64, activation='tanh')(flatten)\n",
    "\n",
    "conc = concatenate([dense1, dense2])\n",
    "\n",
    "output = Dense(10)(conc)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=opt(learning_rate=0.001),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
