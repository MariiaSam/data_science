{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuh08G0+K/KzSJTDD++aQX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5wiwG_W5HomW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def formula(x, y, b):\n",
        "    x = tf.matmul(x, y)\n",
        "    x = x + b\n",
        "    return x\n",
        "\n",
        "\n",
        "function_that_uses_a_graph = tf.function(formula) #  приймає у якості аргумента звичайну функцію і генерує обчислювальний граф\n",
        "\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "orig_value = formula(x1, y1, b1).numpy()\n",
        "tf_function_value = function_that_uses_a_graph(x1, y1, b1).numpy() # тензор, який буде перетворено на багатовимірний масив numpy\n",
        "\n",
        "assert(orig_value == tf_function_value)\n",
        "\n",
        "print(x1.shape)\n",
        "print(y1.shape)\n",
        "print(b1.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX3iYG_7IJDF",
        "outputId": "42f8179c-9b71-430f-8baf-9bd7545bae0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7ac32dd5c580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2)\n",
            "(2, 1)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **для того, щоб отримати тензор маючи багатовимірний масив numpy достатньо виконати наступний код:**"
      ],
      "metadata": {
        "id": "VQMSkZuJJ0cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "x_array = np.array([1, 2, 3])\n",
        "x_tensor = tf.convert_to_tensor(x_array)\n",
        "\n"
      ],
      "metadata": {
        "id": "x7LMc3D1Jjur"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **При цьому перетворення тензора на багатовимірний масив numpy виглядає ще простіше:**"
      ],
      "metadata": {
        "id": "IVa3ASy4J9Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor.numpy()\n"
      ],
      "metadata": {
        "id": "j7WKyUcpKAsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Розглянемо ще один приклад. У нейронних мережах часто використовується активаційна функція ReLU: f(x)=max(x,0)**"
      ],
      "metadata": {
        "id": "eRKOfLbNKvJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def relu_activation(x):\n",
        "    if tf.greater(x, 0):\n",
        "        return x\n",
        "    return 0\n",
        "\n",
        "print(relu_activation(tf.constant(1)).numpy())\n",
        "print(relu_activation(tf.constant(-1)).numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBQ1eseqKrSX",
        "outputId": "6b951845-9b52-401d-eab1-f42c4de156c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Автоматичне диференціювання**"
      ],
      "metadata": {
        "id": "7xUUchD9LPIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def f(x):\n",
        "    return 1 / x ** 2\n",
        "\n",
        "### ***обчислення градієнтів***"
      ],
      "metadata": {
        "id": "Rk6NmFCALSeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Тепер похідну можна обчислити так:***"
      ],
      "metadata": {
        "id": "OIgH14hQN_8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    return 1 / x ** 2\n",
        "\n",
        "\n",
        "x = tf.Variable(2.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = f(x)\n",
        "    dydx = tape.gradient(y, x)\n",
        "    print(dydx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFnyFc4NvcP",
        "outputId": "ffef7a7d-1f76-4f7a-f0fb-82e86f85bbdf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(-0.25, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "За допомогою класу GradientTape tensorflow записує всі операції, необхідні для обчислення похідної в змінну tape.\n",
        "\n",
        "Для того, щоб ***обчислити значення похідної в конкретній точці***, потрібно ***викликати метод gradient***, приймає 2 аргументи. Перший - функція, похідну якої ми хочемо обчислити. Другий - аргумент, за яким обчислюється похідна (причому це може бути тензор). Цей механізм нам ще знадобиться далі.\n",
        "\n"
      ],
      "metadata": {
        "id": "hj-D-x8mOsC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Створення нейронної мережі**"
      ],
      "metadata": {
        "id": "lEwC3wXgO3Ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Нехай потрібно написати примітивну нейронну мережу, яка обчислює значення виразу w⋅x+b.***"
      ],
      "metadata": {
        "id": "bsMjQVzQPJDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class SimpleModule(tf.Module):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.w = tf.Variable(5.0)\n",
        "        self.b = tf.Variable(5.0)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.w * x + self.b\n",
        "\n",
        "\n",
        "simple_module = SimpleModule(name=\"simple\")\n",
        "simple_module(tf.constant(5.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7xNIP-UO75d",
        "outputId": "1af12ffc-00c7-4bfa-ef46-6a37feba89fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Тепер ми можемо спробувати створити складнішу нейронну мережу. Нехай потрібно створити нейромережу, в якій 2 шари. На першому шарі має 3 нейрони з трьома входами, на другому - 1, в якості активаційної функції використовуватимемо ReLU.***"
      ],
      "metadata": {
        "id": "fx1vPM5dPYkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer(tf.Module):\n",
        "    def __init__(self, in_features, out_features, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.w = tf.Variable(\n",
        "            tf.random.normal([in_features, out_features]), name=\"w\"\n",
        "        )\n",
        "        self.b = tf.Variable(tf.zeros([out_features]), name=\"b\")\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y = tf.matmul(x, self.w) + self.b\n",
        "        return tf.nn.relu(y)\n",
        "\n",
        "\n",
        "class NN(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.layer_1 = DenseLayer(in_features=3, out_features=3)\n",
        "    self.layer_2 = DenseLayer(in_features=3, out_features=1)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.layer_1(x)\n",
        "    return self.layer_2(x)\n",
        "\n",
        "\n",
        "nn = NN(name=\"neural_network\")\n",
        "print(\"Results:\", nn(tf.constant([[2.0, 2.0, 2.0]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xTHfOlzPcar",
        "outputId": "8e814f5b-34df-48e0-9c1d-f8de5247d7d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: tf.Tensor([[0.42057833]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***1. Для початку ми створили клас DenseLayer, в якому в загальному вигляді описали перетворення, що відбуваються в цьому шарі:***"
      ],
      "metadata": {
        "id": "UeQS8foaPsw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Навчання нейронної мережі***"
      ],
      "metadata": {
        "id": "NFPIEf4mQ5K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Створимо клас для даної моделі.***"
      ],
      "metadata": {
        "id": "QZiKbbOLRWXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class LinearModel(tf.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.w = tf.Variable(5.0)\n",
        "        self.b = tf.Variable(0.0)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.w * x + self.b\n"
      ],
      "metadata": {
        "id": "83DqxQXfRUjP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Тепер визначимо дві функції: loss та train. Одна буде обчислювати помилку, а друга - підлаштовувати ваги.***"
      ],
      "metadata": {
        "id": "Uo8I-sI7RaCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(target_y, predicted_y):\n",
        "    return tf.reduce_mean(tf.square(target_y - predicted_y))\n",
        "\n",
        "\n",
        "def train(model, x, y, learning_rate):\n",
        "    with tf.GradientTape() as t:\n",
        "        current_loss = loss(y, model(x))\n",
        "        dw, db = t.gradient(current_loss, [model.w, model.b])\n",
        "        model.w.assign_sub(learning_rate * dw)\n",
        "        model.b.assign_sub(learning_rate * db)\n"
      ],
      "metadata": {
        "id": "9e8_9Ib0Rmcj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Для оновлення ваг ми використовуємо метод assign_sub, який веде себе як оператор -=.***"
      ],
      "metadata": {
        "id": "heyQUZkSRsmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, x, y):\n",
        "    for epoch in range(10):\n",
        "        train(model, x, y, learning_rate=0.1)\n",
        "        current_loss = loss(y, model(x))\n",
        "        print(f\"loss: {current_loss}\")\n"
      ],
      "metadata": {
        "id": "wCKAJb1kRwQK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Для того щоб протестувати навчання моделі згенеруємо тестові дані***"
      ],
      "metadata": {
        "id": "ayTEe9yERzAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRUE_W = 3.0\n",
        "TRUE_B = 2.0\n",
        "\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "y = x * TRUE_W + TRUE_B + noise\n"
      ],
      "metadata": {
        "id": "w6cAaVTzR2_H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Тепер зберемо все разом.***"
      ],
      "metadata": {
        "id": "Rjj53nVwR68l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = LinearModel()\n",
        "training_loop(linear_model, x, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkBGTl1zSA-v",
        "outputId": "e30daef5-3273-46ff-fd67-bbbf2a31e5bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 5.876070499420166\n",
            "loss: 4.220036029815674\n",
            "loss: 3.1278774738311768\n",
            "loss: 2.4074106216430664\n",
            "loss: 1.932019829750061\n",
            "loss: 1.6182626485824585\n",
            "loss: 1.411134958267212\n",
            "loss: 1.2743676900863647\n",
            "loss: 1.184039831161499\n",
            "loss: 1.1243698596954346\n"
          ]
        }
      ]
    }
  ]
}