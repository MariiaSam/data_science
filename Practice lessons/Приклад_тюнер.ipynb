{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYt0OTTj6dPN",
        "outputId": "4218da7c-9746-49d2-83b3-c9e4be1629a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/129.1 kB\u001b[0m \u001b[31m934.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/129.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "IRm-HVXLvxoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження набору даних Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"x_train original shape\", x_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "MqT3qhT_v0P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaDzFmCr6Vw0",
        "outputId": "aa42008b-917a-4153-d1d2-d0352abca293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 16m 30s]\n",
            "val_accuracy: 0.869700014591217\n",
            "\n",
            "Best val_accuracy So Far: 0.8996999859809875\n",
            "Total elapsed time: 02h 36m 25s\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 480)               376800    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 480)               1920      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               61568     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 96)                384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                970       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 454538 (1.73 MB)\n",
            "Trainable params: 453130 (1.73 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 27s 13ms/step - loss: 0.2842 - accuracy: 0.9179 - val_loss: 0.3617 - val_accuracy: 0.8972 - lr: 2.5000e-05\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2823 - accuracy: 0.9183 - val_loss: 0.3625 - val_accuracy: 0.8977 - lr: 2.5000e-05\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2808 - accuracy: 0.9193 - val_loss: 0.3536 - val_accuracy: 0.8961 - lr: 2.5000e-05\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2782 - accuracy: 0.9202 - val_loss: 0.3544 - val_accuracy: 0.8967 - lr: 2.5000e-05\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2782 - accuracy: 0.9199 - val_loss: 0.3581 - val_accuracy: 0.8970 - lr: 2.5000e-05\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2740 - accuracy: 0.9205 - val_loss: 0.3568 - val_accuracy: 0.8976 - lr: 2.5000e-05\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2663 - accuracy: 0.9236 - val_loss: 0.3495 - val_accuracy: 0.8987 - lr: 1.2500e-05\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2638 - accuracy: 0.9248 - val_loss: 0.3507 - val_accuracy: 0.8990 - lr: 1.2500e-05\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2595 - accuracy: 0.9263 - val_loss: 0.3507 - val_accuracy: 0.9001 - lr: 1.2500e-05\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2590 - accuracy: 0.9262 - val_loss: 0.3512 - val_accuracy: 0.8984 - lr: 1.2500e-05\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2520 - accuracy: 0.9280 - val_loss: 0.3528 - val_accuracy: 0.8987 - lr: 6.2500e-06\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2490 - accuracy: 0.9304 - val_loss: 0.3504 - val_accuracy: 0.9016 - lr: 6.2500e-06\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2480 - accuracy: 0.9302 - val_loss: 0.3512 - val_accuracy: 0.8999 - lr: 6.2500e-06\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2472 - accuracy: 0.9303 - val_loss: 0.3475 - val_accuracy: 0.9021 - lr: 3.1250e-06\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2460 - accuracy: 0.9314 - val_loss: 0.3492 - val_accuracy: 0.9004 - lr: 3.1250e-06\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2458 - accuracy: 0.9307 - val_loss: 0.3498 - val_accuracy: 0.9004 - lr: 3.1250e-06\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2443 - accuracy: 0.9314 - val_loss: 0.3482 - val_accuracy: 0.9008 - lr: 3.1250e-06\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2426 - accuracy: 0.9316 - val_loss: 0.3485 - val_accuracy: 0.9007 - lr: 1.5625e-06\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2416 - accuracy: 0.9323 - val_loss: 0.3490 - val_accuracy: 0.9016 - lr: 1.5625e-06\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2410 - accuracy: 0.9329 - val_loss: 0.3495 - val_accuracy: 0.9018 - lr: 1.5625e-06\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2436 - accuracy: 0.9318 - val_loss: 0.3483 - val_accuracy: 0.9019 - lr: 1.0000e-06\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2423 - accuracy: 0.9327 - val_loss: 0.3493 - val_accuracy: 0.9016 - lr: 1.0000e-06\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2393 - accuracy: 0.9330 - val_loss: 0.3493 - val_accuracy: 0.9016 - lr: 1.0000e-06\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2408 - accuracy: 0.9322 - val_loss: 0.3501 - val_accuracy: 0.9022 - lr: 1.0000e-06\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2402 - accuracy: 0.9327 - val_loss: 0.3498 - val_accuracy: 0.9017 - lr: 1.0000e-06\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2388 - accuracy: 0.9331 - val_loss: 0.3495 - val_accuracy: 0.9013 - lr: 1.0000e-06\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2399 - accuracy: 0.9333 - val_loss: 0.3497 - val_accuracy: 0.9020 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2421 - accuracy: 0.9319 - val_loss: 0.3487 - val_accuracy: 0.9020 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2394 - accuracy: 0.9329 - val_loss: 0.3502 - val_accuracy: 0.9024 - lr: 1.0000e-06\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.9021\n",
            "Test accuracy: 0.9021000266075134\n",
            "Test loss: 0.3474977910518646\n"
          ]
        }
      ],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    # Додавання шарів, які будуть тюнуватися\n",
        "    for i in range(hp.Int('num_layers', 1, 4)):\n",
        "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
        "                                     min_value=32,\n",
        "                                     max_value=512,\n",
        "                                     step=32),\n",
        "                        activation='relu',\n",
        "                        kernel_regularizer=l2(0.001)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Компіляція моделі з оптимізатором, який також буде тюнуватися\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  # збільшення кількості спроб для кращих результатів\n",
        "    executions_per_trial=1,\n",
        "    directory='tuner_logs',\n",
        "    project_name='fashion_mnist_classification'\n",
        ")\n",
        "\n",
        "# Визначення ранньої зупинки та зниження швидкості навчання\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Отримання найкращої моделі\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.summary()\n",
        "\n",
        "# Тренування та оцінка моделі\n",
        "best_model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)\n"
      ]
    }
  ]
}